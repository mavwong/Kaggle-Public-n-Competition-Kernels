{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Overview\n\n  - Import Dependencies\n  - Output File\n  - Data Preparation\n  - Data Generator / Data Augmentation\n  - Data Exploration\n  - Callbacks\n  - Model Architecture\n  - Evaluation\n  - Saving and Loading the Model\n  - Testing the Model\n  - Reference"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### **1. Import Dependencies**"},{"metadata":{"trusted":true,"_uuid":"abc97340d2e2159a5feb475c8649536f4d24c79c"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#High Level Operations on Files and Collection of Files\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aae9646f567ace5f5f87c5a6572ae898bd85b93b"},"cell_type":"code","source":"from glob import glob   # Finds all the pathnames matching a specified pattern\nfrom skimage.io import imread   #Loading an image from a file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88b2771859f8b163b800c846e5ba74732a5d629d"},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cf774c7152ab0d1ebaf413f305a84b69c93d13c"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.applications.xception import Xception\n\nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, Concatenate, GlobalMaxPooling2D, BatchNormalization\nfrom keras.models import Model\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b53294e393a9a1d03ed2e8395f9700076e457b8e"},"cell_type":"code","source":"!pip install livelossplot\nfrom livelossplot import PlotLossesKeras","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a6ff3358ad9ee035187726476b81e573de3c578"},"cell_type":"markdown","source":"### **2. Output Files / Parameters of the Model**"},{"metadata":{"trusted":true,"_uuid":"4aca7252dcc725f92bc1e997bb34efae44784a81"},"cell_type":"code","source":"TRAINING_LOGS_FILE = 'training_logs.csv'\nMODEL_SUMMARY_FILE = 'model.summary.txt'\nMODEL_FILE = 'histopathologic_cancer_detector.h5'\n\nTRAINING_PLOT_FILE = 'training.png'\nVALIDATION_PLOT_FILE = 'validation.png'\nROC_PLOT_FILE = 'roc.png'\n\nKAGGLE_SUBMISSION_FILE = 'kaggle_submission.csv'\nINPUT_DIRECTORY = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aca8f0a26a4782c2b7a735c9a2ebe8eb4532b1c"},"cell_type":"code","source":"test_run = False\n\nSAMPLE_COUNT = 85000\nTRAINING_RATIO = 0.9\nVERBOSITY = 1\nTESTING_BATCH_SIZE = 5000\n\nif test_run == True:\n    NUM_EPOCHS = 5\nelse:\n    NUM_EPOCHS = 100\n\nIMG_HEIGHT = 96\nIMG_WIDTH = 96\nIMG_CHANNEL = 3\nIMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\nBATCH_SIZE = 216","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3012691251a92a31640738b2a657eb16e07d58dd"},"cell_type":"markdown","source":"### **3. Data Preparation**"},{"metadata":{"trusted":true,"_uuid":"adec5d447cdc26bd120eecf79bcf81a2138861d1"},"cell_type":"code","source":"#Training Directory\ntraining_dir = INPUT_DIRECTORY + 'train/'\n\n#Creating CSV File\ndata_frame = pd.DataFrame({'path': glob(os.path.join(training_dir, '*tif'))})\ndata_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split('.')[0])\n\n#Importing or Reading CSV file\nlabels = pd.read_csv(INPUT_DIRECTORY + 'train_labels.csv')\ndata_frame = data_frame.merge(labels, on='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66490f25a55b0751eb27e182179528e67cfbb1d0"},"cell_type":"code","source":"#Getting the negatives and positives\nnegatives = data_frame[data_frame.label == 0].sample(SAMPLE_COUNT)\npositives = data_frame[data_frame.label == 1].sample(SAMPLE_COUNT)\n\ndata_frame = pd.concat([negatives, positives]).reset_index()   #Concat and Reseting index\ndata_frame = data_frame[['path', 'id', 'label']]        #Removing unnecessary columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f71d1b7b7c354ecd083f8cbd068d86d8b22998ef"},"cell_type":"code","source":"data_frame.image = data_frame.path.map(imread)   #Replacing?!?!?!?!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd4b0a44c8fddeed5e73141deef8b89cccf6c7c3"},"cell_type":"code","source":"training_path = '../training'\nvalidation_path = '../validation'\n\nfor folder in [training_path, validation_path]:\n    for subfolder in ['0', '1']:\n        path = os.path.join(folder, subfolder)\n        os.makedirs(path, exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5e648d87148dcfff39737343af38eb2b80a87634"},"cell_type":"code","source":"training, validation = train_test_split(data_frame, \n                                        train_size=TRAINING_RATIO, \n                                        stratify=data_frame['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06e67c3d7757da738f28732781ce70e067c9cde9"},"cell_type":"code","source":"data_frame.set_index('id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93830efe1208225e7122f3045bcda08baba6fb6e"},"cell_type":"code","source":"for images_and_path in [(training, training_path), (validation, validation_path)]:\n    images = images_and_path[0]\n    path = images_and_path[1]\n    for image in images['id'].values:\n        file_name = image + '.tif'\n        label = str(data_frame.loc[image,'label'])\n        destination = os.path.join(path, label, file_name)\n        \n        if not os.path.exists(destination):\n            source = os.path.join(INPUT_DIRECTORY + 'train', file_name)\n            shutil.copyfile(source, destination)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccc4e1b1c4c9d77d1be4e3f007b1c9c2e1dcf537"},"cell_type":"markdown","source":"### **4. Data Generator / Data Augmentation**"},{"metadata":{"trusted":true,"_uuid":"f0b18504a70f624b7e7ff8aacbbad86f52de139b"},"cell_type":"code","source":"### Data Augmentation / Data Generation\ntraining_data_generator = ImageDataGenerator(rescale=1./255,\n                                             horizontal_flip=True,\n                                             vertical_flip=True,\n                                             rotation_range=90,\n                                             zoom_range=0.2, \n                                             width_shift_range=0.1,\n                                             height_shift_range=0.1,\n                                             shear_range=0.05,\n                                             channel_shift_range=0.1)\n                                             \ntraining_generator = training_data_generator.flow_from_directory(training_path,\n                                                                 target_size=IMG_SIZE,\n                                                                 batch_size=BATCH_SIZE,\n                                                                 class_mode='binary')\n\nvalidation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n                                                                              target_size=IMG_SIZE,\n                                                                              batch_size=BATCH_SIZE,\n                                                                              class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87d04ded9bedb27013193218f167070a789fac18"},"cell_type":"markdown","source":"### **5. Callbacks**"},{"metadata":{"trusted":true,"_uuid":"94f6a537724e91dccfd1099eae23566cd9dd8e1a"},"cell_type":"code","source":"### CALLBACKS\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TerminateOnNaN, TensorBoard\n\ncsv_logger = CSVLogger(TRAINING_LOGS_FILE, \n                       append=False, \n                       separator = ';')\n\nmodel_checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_acc', \n                                   verbose = VERBOSITY, \n                                   save_best_only=True, \n                                   mode='max')\n\ncallback = [PlotLossesKeras(), csv_logger, model_checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d310262c9ecbe87357803c519f07f27f7cd6de47"},"cell_type":"markdown","source":"### **6. Model Architecture**"},{"metadata":{"trusted":true,"_uuid":"4d4791ccc612a6b48fc588afdea3c1de3af83d93"},"cell_type":"code","source":"input_shape = IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL\ninputs = Input(input_shape)\n\nxception_model = Xception(include_top=False, weights='imagenet')\nnasnet_model = NASNetMobile(include_top=False, weights='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d385badf289ffd9c94110f76bea5e3d6b7412c8d"},"cell_type":"code","source":"#Freezing some layer\nfor layer in xception_model.layers[:-10]:\n    layer.trainable = False\n\n'''for layer in xception_model.layers:\n    print(layer, layer.trainable)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe0984ea034f08754d7077b416cc12e4901082c"},"cell_type":"code","source":"#Freezing some of the layers\nfor layer in nasnet_model.layers[:-44]:\n    layer.trainable = False\n\n'''for layer in nasnet_model.layers:\n    print(layer, layer.trainable)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c33c209f6f9d54f5a688e7ef389b7a1451330da"},"cell_type":"code","source":"outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception_model(inputs)),\n                                GlobalAveragePooling2D()(nasnet_model(inputs))])\n\noutputs = Dropout(0.55)(outputs)\noutputs = Dense(1, activation='sigmoid')(outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34d51e78ae73a09edc7909def8f0f5f7cc1cdcea"},"cell_type":"code","source":"final_model = Model(inputs, outputs)\nfinal_model.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\n#final_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ecd2bb910276479a2eda40be2a063aa9207cc3c"},"cell_type":"code","source":"'''from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nSVG(model_to_dot(final_model).create(prog='dot', format='svg'))\n\nfrom keras.utils.vis_utils import plot_model\nplot_model(final_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5a27b4f8c6debc3721cd9344e87f80c7dc7d3b0"},"cell_type":"code","source":"final_model_history = final_model.fit_generator(training_generator,\n                              steps_per_epoch=len(training_generator), \n                              validation_data=validation_generator,\n                              validation_steps=len(validation_generator),\n                              epochs=NUM_EPOCHS,\n                              verbose=VERBOSITY,\n                              callbacks=callback)\n\nfinal_model.load_weights(MODEL_FILE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38c1d2cc8649a4940f9b384402e88a39777eeab6"},"cell_type":"markdown","source":"### **7. Evaluation / Showing the Result**"},{"metadata":{"trusted":true,"_uuid":"0c70d2a3d2ca64bfb2f0c89c1e728e7b0c3b0feb"},"cell_type":"code","source":"epochs = [i for i in range(1, len(final_model_history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('training')\nplt.xlabel('epoch')\nplt.savefig(TRAINING_PLOT_FILE, bbox_inches='tight')\nplt.show()\n\nplt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('validation')\nplt.xlabel('epoch')\nplt.savefig(VALIDATION_PLOT_FILE, bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17c0a45cd836f864c45ed53e2780f4679262cda6"},"cell_type":"markdown","source":"### **8. Submission**"},{"metadata":{"trusted":true,"_uuid":"be3d485414f22212a347af560960ff3587236e5c"},"cell_type":"code","source":"testing_files = glob(os.path.join(INPUT_DIRECTORY+'test/','*.tif'))\n\n#Creating a dataframe\nsubmission = pd.DataFrame()\nfor index in range(0, len(testing_files), TESTING_BATCH_SIZE):\n    data_frame = pd.DataFrame({'path': testing_files[index:index+TESTING_BATCH_SIZE]})\n    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n    data_frame['image'] = data_frame['path'].map(imread)\n    images = np.stack(data_frame.image, axis=0)\n    \n    predicted_labels = [final_model.predict(np.expand_dims(image/255.0, axis=0))[0][0] for image in images]\n    predictions = np.array(predicted_labels)\n    data_frame['label'] = predictions\n    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\nsubmission.to_csv(KAGGLE_SUBMISSION_FILE, index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e05d9f2ac2fc7e31a1fec77ab66ee0b4d14b3c6c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}